# iSAM
This project fine-tunes an affective model to player nuances using the SAM (Self-Assessment Manikin) and immersive media (HTC Vive and Unity VR). We train a base model using ResNet50 features and a convolution layer on the International Affective Picture system database, and fine-tune the base model on user responses collected during interactions. After a set of interactions, we predict a picture that the user would like based on the fine-tuned model and evaluate the improvement of the fine-tuned model over the base model.

This is an empty repo that only holds the description of the project.

Working repo [here](https://github.com/avivelor/UntitledMemoryProject) (this is private now but may be made public later).

Paper [here](#) (link under construction; working on the camera-ready copy!).

#### This is the software strucure for iSAM
![](UnityFlow_2.png)

#### This is the predictions of pictures for 4 players, post tuning
![](Unity_Images.JPG)

# Target Unity Version: 2019.2.11f1
@ Group: Aviv Elor and Asiiah Song
